{"cells":[{"cell_type":"markdown","metadata":{"id":"b518b04cbfe0"},"source":["# Generative Adversarial Networks "]},{"cell_type":"markdown","metadata":{"id":"9fb325331a1e"},"source":["A GAN is made of two parts: a \"generator\" model that maps points in the latent\n","space to points in image space, a \"discriminator\" model, a classifier\n","that can tell the difference between real images (from the training dataset)\n","and fake images (the output of the generator network).\n","\n","A GAN training loop looks like this:\n","\n","1) Train the discriminator.\n","- Sample a batch of random points in the latent space.\n","- Turn the points into fake images via the \"generator\" model.\n","- Get a batch of real images and combine them with the generated images.\n","- Train the \"discriminator\" model to classify generated vs. real images.\n","\n","2) Train the generator.\n","- Sample random points in the latent space.\n","- Turn the points into fake images via the \"generator\" network.\n","- Get a batch of real images and combine them with the generated images.\n","- Train the \"generator\" model to \"fool\" the discriminator and classify the fake images\n","as real.\n","\n","For a much more detailed overview of how GANs works, see\n","[Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python).\n","\n","Let's implement this training loop. First, create the discriminator meant to classify\n","fake vs real digits:"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":961,"status":"ok","timestamp":1606337628739,"user":{"displayName":"Gianluigi Greco","photoUrl":"","userId":"11427474386667803728"},"user_tz":-60},"id":"fabf9cef3400","outputId":"9b3bf269-0ac9-4824-fbc8-5832efde059c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"discriminator\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 14, 14, 64)        640       \n","_________________________________________________________________\n","leaky_re_lu (LeakyReLU)      (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 7, 7, 128)         73856     \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","global_max_pooling2d (Global (None, 128)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 1)                 129       \n","=================================================================\n","Total params: 74,625\n","Trainable params: 74,625\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["import keras\n","from keras import layers\n","\n","discriminator = keras.Sequential(\n","    [\n","        keras.Input(shape=(28, 28, 1)),\n","        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.GlobalMaxPooling2D(),\n","        layers.Dense(1),\n","    ],\n","    name=\"discriminator\",\n",")\n","discriminator.summary()"]},{"cell_type":"markdown","metadata":{"id":"73396eb6daf9"},"source":["Then let's create a generator network,\n","that turns latent vectors into outputs of shape `(28, 28, 1)` (representing\n","MNIST digits):"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":830,"status":"ok","timestamp":1606337890240,"user":{"displayName":"Gianluigi Greco","photoUrl":"","userId":"11427474386667803728"},"user_tz":-60},"id":"821d203bfb3e","outputId":"80501dc6-76d4-49ce-d552-780c140be765"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"generator\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_2 (Dense)              (None, 6272)              809088    \n","_________________________________________________________________\n","leaky_re_lu_5 (LeakyReLU)    (None, 6272)              0         \n","_________________________________________________________________\n","reshape_1 (Reshape)          (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","conv2d_transpose_2 (Conv2DTr (None, 14, 14, 128)       262272    \n","_________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 128)       0         \n","_________________________________________________________________\n","conv2d_transpose_3 (Conv2DTr (None, 28, 28, 128)       262272    \n","_________________________________________________________________\n","leaky_re_lu_7 (LeakyReLU)    (None, 28, 28, 128)       0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 28, 28, 1)         6273      \n","=================================================================\n","Total params: 1,339,905\n","Trainable params: 1,339,905\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["latent_dim = 128\n","\n","generator = keras.Sequential(\n","    [\n","        keras.Input(shape=(latent_dim,)),\n","        # We want to generate 128 coefficients to reshape into a 7x7x128 map\n","        layers.Dense(7 * 7 * 128),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Reshape((7, 7, 128)),\n","        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n","    ],\n","    name=\"generator\",\n",")\n","generator.summary()"]},{"cell_type":"markdown","metadata":{"id":"f0d6d54a78a0"},"source":["Here's the key bit: the training loop. As you can see it is quite straightforward. The\n","training step function only takes 17 lines."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1091,"status":"ok","timestamp":1606338374671,"user":{"displayName":"Gianluigi Greco","photoUrl":"","userId":"11427474386667803728"},"user_tz":-60},"id":"3a11c875142e"},"outputs":[],"source":["import tensorflow as tf\n","\n","# Instantiate one optimizer for the discriminator and another for the generator.\n","d_optimizer = keras.optimizers.Adam(learning_rate=0.0003)\n","g_optimizer = keras.optimizers.Adam(learning_rate=0.0004)\n","\n","# Instantiate a loss function.\n","loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n","\n","\n","@tf.function\n","def train_step(real_images):\n","    # Sample random points in the latent space\n","    random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n","    # Decode them to fake images\n","    generated_images = generator(random_latent_vectors)\n","    # Combine them with real images\n","    combined_images = tf.concat([generated_images, real_images], axis=0)\n","\n","    # Assemble labels discriminating real from fake images\n","    labels = tf.concat(\n","        [tf.ones((batch_size, 1)), tf.zeros((real_images.shape[0], 1))], axis=0\n","    )\n","    # Add random noise to the labels - important trick!\n","    labels += 0.05 * tf.random.uniform(labels.shape)\n","\n","    # Train the discriminator\n","    with tf.GradientTape() as tape:\n","        predictions = discriminator(combined_images)\n","        d_loss = loss_fn(labels, predictions)\n","    grads = tape.gradient(d_loss, discriminator.trainable_weights)\n","    d_optimizer.apply_gradients(zip(grads, discriminator.trainable_weights))\n","\n","    # Sample random points in the latent space\n","    random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n","    # Assemble labels that say \"all real images\"\n","    misleading_labels = tf.zeros((batch_size, 1))\n","\n","    # Train the generator (note that we should *not* update the weights\n","    # of the discriminator)!\n","    with tf.GradientTape() as tape:\n","        predictions = discriminator(generator(random_latent_vectors))\n","        g_loss = loss_fn(misleading_labels, predictions)\n","    grads = tape.gradient(g_loss, generator.trainable_weights)\n","    g_optimizer.apply_gradients(zip(grads, generator.trainable_weights))\n","    return d_loss, g_loss, generated_images\n"]},{"cell_type":"markdown","metadata":{"id":"fa6bd6292488"},"source":["Let's train our GAN, by repeatedly calling `train_step` on batches of images.\n","\n","Since our discriminator and generator are convnets, you're going to want to\n","run this code on a GPU."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"b6a4e3d42262"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Start epoch 0\n","discriminator loss at step 0: 0.61\n","adversarial loss at step 0: 0.75\n","\n","Start epoch 1\n","discriminator loss at step 0: 0.48\n","adversarial loss at step 0: 0.94\n","\n","Start epoch 2\n","discriminator loss at step 0: 0.47\n","adversarial loss at step 0: 0.72\n","\n","Start epoch 3\n","discriminator loss at step 0: 0.41\n","adversarial loss at step 0: 0.75\n","\n","Start epoch 4\n","discriminator loss at step 0: 0.38\n","adversarial loss at step 0: 0.76\n","\n","Start epoch 5\n","discriminator loss at step 0: 0.62\n","adversarial loss at step 0: 0.49\n","\n","Start epoch 6\n","discriminator loss at step 0: 0.44\n","adversarial loss at step 0: 1.13\n","\n","Start epoch 7\n","discriminator loss at step 0: 0.37\n","adversarial loss at step 0: 1.34\n","\n","Start epoch 8\n","discriminator loss at step 0: 0.24\n","adversarial loss at step 0: 1.55\n","\n","Start epoch 9\n","discriminator loss at step 0: 0.32\n","adversarial loss at step 0: 1.28\n","\n","Start epoch 10\n","discriminator loss at step 0: 0.35\n","adversarial loss at step 0: 1.70\n","\n","Start epoch 11\n","discriminator loss at step 0: 0.27\n","adversarial loss at step 0: 1.70\n","\n","Start epoch 12\n","discriminator loss at step 0: 0.43\n","adversarial loss at step 0: 1.11\n","\n","Start epoch 13\n","discriminator loss at step 0: 0.34\n","adversarial loss at step 0: 1.05\n","\n","Start epoch 14\n","discriminator loss at step 0: 0.23\n","adversarial loss at step 0: 1.50\n","\n","Start epoch 15\n","discriminator loss at step 0: 0.14\n","adversarial loss at step 0: 1.97\n","\n","Start epoch 16\n","discriminator loss at step 0: 0.22\n","adversarial loss at step 0: 1.36\n","\n","Start epoch 17\n","discriminator loss at step 0: 0.45\n","adversarial loss at step 0: 1.91\n","\n","Start epoch 18\n","discriminator loss at step 0: 0.52\n","adversarial loss at step 0: 1.07\n","\n","Start epoch 19\n","discriminator loss at step 0: 0.56\n","adversarial loss at step 0: 1.05\n"]}],"source":["import os\n","import numpy as np\n","\n","\n","# Prepare the dataset. We use both the training \u0026 test MNIST digits.\n","batch_size = 64\n","(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n","all_digits = np.concatenate([x_train, x_test])\n","all_digits = all_digits.astype(\"float32\") / 255.0\n","all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n","dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n","dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n","\n","epochs = 20  # In practice you need at least 20 epochs to generate nice digits.\n","save_dir = \"./\"\n","\n","for epoch in range(epochs):\n","    print(\"\\nStart epoch\", epoch)\n","\n","    for step, real_images in enumerate(dataset):\n","        # Train the discriminator \u0026 generator on one batch of real images.\n","        d_loss, g_loss, generated_images = train_step(real_images)\n","\n","        # Logging.\n","        if step % 200 == 0:\n","            # Print metrics\n","            print(\"discriminator loss at step %d: %.2f\" % (step, d_loss))\n","            print(\"adversarial loss at step %d: %.2f\" % (step, g_loss))\n","\n","            # Save one generated image\n","            img = tf.keras.preprocessing.image.array_to_img(\n","                generated_images[0] * 255.0, scale=False\n","            )\n","            img.save(os.path.join(save_dir, \"generated_img\" + str(step) + \".png\"))\n","\n","        # To limit execution time we stop after 10 steps.\n","        # Remove the lines below to actually train the model!\n","        if step \u003e 10:\n","            break"]},{"cell_type":"markdown","metadata":{"id":"a92959ac630b"},"source":["That's it! You'll get nice-looking fake MNIST digits after just ~30s of training on the\n","Colab GPU."]}],"metadata":{"colab":{"collapsed_sections":[],"name":"GAN.ipynb","provenance":[{"file_id":"https://github.com/tensorflow/docs/blob/snapshot-keras/site/en/guide/keras/writing_a_training_loop_from_scratch.ipynb","timestamp":1606337437920}],"toc_visible":true,"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}