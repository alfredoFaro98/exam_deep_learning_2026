{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOF5bsOWmuzAF3Y7j9NNwkC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Tensorflow Subclassing and Custom Loop**"],"metadata":{"id":"D_MtR7zzxZuJ"}},{"cell_type":"markdown","source":["Import Libraries"],"metadata":{"id":"1yPQ6Bk5xquy"}},{"cell_type":"code","source":["import tensorflow as tf\n","from keras import layers, metrics, losses\n","from keras.datasets import mnist"],"metadata":{"id":"pRgKkiyPRPqN","executionInfo":{"status":"ok","timestamp":1730974376637,"user_tz":-60,"elapsed":478,"user":{"displayName":"Carlo Adornetto","userId":"12456770947398655820"}}},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":["###Multiclass Classification task on Mnist dataset.\n","\n","First, let's load and visualize the dataset"],"metadata":{"id":"lsOZOvmwxzNp"}},{"cell_type":"code","source":["(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalization"],"metadata":{"id":"G_9bQKP-RSeZ","executionInfo":{"status":"ok","timestamp":1730974377580,"user_tz":-60,"elapsed":490,"user":{"displayName":"Carlo Adornetto","userId":"12456770947398655820"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["x_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iumle47Vyp5g","executionInfo":{"status":"ok","timestamp":1730974377580,"user_tz":-60,"elapsed":3,"user":{"displayName":"Carlo Adornetto","userId":"12456770947398655820"}},"outputId":"7c7fc25b-6c29-4a09-b373-ceb6436391db"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 28, 28)"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","fig, axes = plt.subplots(3, 3, figsize=(8, 8))\n","axes = axes.flatten()\n","for i in range(9):\n","  random_index = np.random.randint(0, len(x_train))\n","  image = x_train[random_index]\n","  label = y_train[random_index]\n","  axes[i].imshow(image, cmap='gray')\n","  axes[i].set_title(f\"Label: {label}\")\n","  axes[i].axis('off')\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":807},"id":"PpSr6b3P9cc-","executionInfo":{"status":"ok","timestamp":1730974378235,"user_tz":-60,"elapsed":657,"user":{"displayName":"Carlo Adornetto","userId":"12456770947398655820"}},"outputId":"0183e224-61ab-43bb-f011-daf6fc9ee915"},"execution_count":49,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 800x800 with 9 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# If you want to work with images add the channel dimension\n","#x_train = x_train[..., tf.newaxis]\n","#x_test = x_test[..., tf.newaxis]\n","#x_train.shape"],"metadata":{"id":"MrSTRXoMySJv","executionInfo":{"status":"ok","timestamp":1730974378235,"user_tz":-60,"elapsed":5,"user":{"displayName":"Carlo Adornetto","userId":"12456770947398655820"}}},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":["Let's define our model by extending the base class ```Model``` provided by Keras.\n","\n","2 key elements:\n","- **Constructor**: define attributes, layers and every characteristic of the model\n","- **call function**: It defines the operation that the model execute when it is colled for inference (e.g. in the forward pass)  "],"metadata":{"id":"gGqaBFqP0Sqe"}},{"cell_type":"code","source":["class MyModel(tf.keras.Model):\n","    def __init__(self):\n","        super(MyModel, self).__init__()\n","        self.flatten = layers.Flatten()\n","        self.dense1 = layers.Dense(64, activation='relu')\n","        self.dense2 = layers.Dense(10)\n","\n","    def call(self, inputs):\n","        x = self.flatten(inputs)\n","        x = self.dense1(x)\n","        return self.dense2(x)\n","\n","# Create an instance of the model\n","model = MyModel()\n","\n","# Invoke the Call function (result will be the activations of the last dense layer)\n","model(tf.random.normal((1, 28, 28)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KDyLiID2RYaf","executionInfo":{"status":"ok","timestamp":1730974378235,"user_tz":-60,"elapsed":4,"user":{"displayName":"Carlo Adornetto","userId":"12456770947398655820"}},"outputId":"d4c65361-3311-4299-ed24-b29439fc33c8"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n","array([[-0.51978856, -1.4806361 , -0.8978178 , -0.86791015,  1.1448257 ,\n","        -1.0020833 , -0.49600184,  0.04873192,  0.679409  ,  0.53839004]],\n","      dtype=float32)>"]},"metadata":{},"execution_count":51}]},{"cell_type":"markdown","source":["Let's define a custom loss function by extending the base class ```Loss``` provided by Keras."],"metadata":{"id":"Oebq55RP2JbC"}},{"cell_type":"code","source":["# Definisci una funzione di perdita custom\n","class SparseCategoricalCrossentropyCustom(losses.Loss):\n","    def call(self, y_true, y_pred):\n","        y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=10)\n","        loss = -tf.reduce_sum(y_true * tf.math.log(tf.nn.softmax(y_pred) + 1e-10), axis=1)\n","        return tf.reduce_mean(loss)"],"metadata":{"id":"0Qm1--ERRfdu","executionInfo":{"status":"ok","timestamp":1730974378235,"user_tz":-60,"elapsed":4,"user":{"displayName":"Carlo Adornetto","userId":"12456770947398655820"}}},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":["Let's define a custom metric function by extending the base class ```Metric``` provided by Keras.\n","\n","Key elements:\n","- **constructor**: it might contain metric variables, counters, scaling factors.\n","- **update state**: called after each batch\n","- **result**: called to retreive the **current** value of the metric\n","- **reset_state**: called at the end of each epoch\n","\n","It is intended as cumulative: collect the results of each batch during traininf loop, and than aggregate!\n","\n","**NOTE:** ```add_weight``` <ins>when used in Metrics class it doesn't create trainable weights</ins>. It is used to create optimized version of a variable that can be treated more efficiently. Out of the Metrics context, it is usually called to create trainable weights.  "],"metadata":{"id":"wRI32IyS2dCN"}},{"cell_type":"code","source":["# Definisci metriche custom\n","class AccuracyCustom(metrics.Metric):\n","    def __init__(self, name='accuracy_custom', **kwargs):\n","        super(AccuracyCustom, self).__init__(name=name, **kwargs)\n","        self.accuracy = self.add_weight(name='accuracy', initializer='zeros')\n","        self.total = self.add_weight(name='total', initializer='zeros')\n","\n","    def update_state(self, y_true, y_pred, sample_weight=None):\n","        y_pred = tf.argmax(y_pred, axis=1)\n","        matches = tf.equal(tf.cast(y_true, tf.int64), y_pred)\n","        self.accuracy.assign_add(tf.reduce_sum(tf.cast(matches, tf.float32)))\n","        self.total.assign_add(tf.cast(tf.size(y_true), tf.float32))\n","\n","    def result(self):\n","        return self.accuracy / self.total\n","\n","    def reset_states(self):\n","        self.accuracy.assign(0)\n","        self.total.assign(0)"],"metadata":{"id":"HkkPkbLORhBs","executionInfo":{"status":"ok","timestamp":1730974378235,"user_tz":-60,"elapsed":3,"user":{"displayName":"Carlo Adornetto","userId":"12456770947398655820"}}},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":["### Managing Data\n","The `tf.data.Dataset.from_tensor_slices` function in TensorFlow creates a `Dataset` object from a set of data (arrays, tensors, or any compatible sequence of data). This function \"slices\" the input along the first dimension, creating a data structure that can generate mini-batches for training.\n","\n","Key concepts:\n","\n","1. **Input**: The function can take arrays of data such as NumPy arrays, TensorFlow tensors, or lists. If there are multiple inputs, they must have the same length along the first dimension, as they will be paired element by element.\n","  \n","2. **Output**: It creates a dataset containing individual elements \"sliced\" along the first dimension. For example, if you provide an array with dimensions `(60000, 28, 28)` (like `x_train` in the MNIST dataset), `from_tensor_slices` will create a dataset with 60,000 samples, each of shape `(28, 28)`.\n","\n","3. **Common Uses**: This function is useful for creating datasets compatible with training that can be manipulated with methods such as `.batch()`, `.shuffle()`, and `.repeat()` to build custom data pipelines.\n","\n","**Long story short**: Easily create iterable of batches and apply all the needed preprocessing operations."],"metadata":{"id":"fkAKhUQMya-j"}},{"cell_type":"code","source":["epochs = 5\n","batch_size = 256\n","train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n","test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)"],"metadata":{"id":"nuAbsFR09XBW","executionInfo":{"status":"ok","timestamp":1730974380101,"user_tz":-60,"elapsed":1869,"user":{"displayName":"Carlo Adornetto","userId":"12456770947398655820"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["# Instantiate everything you need to train the model\n","loss_fn = SparseCategoricalCrossentropyCustom()\n","train_acc_metric = AccuracyCustom()\n","val_acc_metric = AccuracyCustom()\n","\n","optimizer = tf.keras.optimizers.Adam()\n","model = MyModel()"],"metadata":{"id":"oImz_hX87jhb","executionInfo":{"status":"ok","timestamp":1730974380101,"user_tz":-60,"elapsed":4,"user":{"displayName":"Carlo Adornetto","userId":"12456770947398655820"}}},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":["## Customized Training Loop\n","#### What appens in the `fit()` function\n","\n","\n","Key lines of code:\n","```python\n","grads = tape.gradient(loss_value, model.trainable_weights)\n","optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","```\n","\n","1. **Compute Gradients** (`tape.gradient()`):\n","   - Here, `tape.gradient` calculates the gradient of `loss_value` with respect to the model’s trainable weights.\n","   - `tape` is a `tf.GradientTape` context that records all operations on tensors watched during the forward pass, allowing us to compute gradients for backpropagation.\n","   - `loss_value` is the loss calculated for the current batch.\n","   - `model.trainable_weights` represents all weights in the model that need to be updated during training.\n","   - The result, `grads`, is a list of gradients (one per trainable weight in the model) that shows how each weight should be adjusted to reduce the loss.\n","\n","2. **Apply Gradients** (`optimizer.apply_gradients()`):\n","   - This line uses the optimizer (e.g., Adam, SGD) to update the model's weights based on the gradients calculated.\n","   - `zip(grads, model.trainable_weights)` pairs each gradient with its corresponding weight, creating a list of `(gradient, weight)` tuples.\n","   - `optimizer.apply_gradients` then updates each weight by subtracting a fraction of the gradient (the learning rate determines this fraction) to minimize the loss.\n","   \n","**Long story short**: In essence, this step updates the model’s parameters in the direction that should reduce the loss, following the rules of the specified optimizer."],"metadata":{"id":"wAomD-R6-NMy"}},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iaVI4lFW_wo1","executionInfo":{"status":"ok","timestamp":1730974425729,"user_tz":-60,"elapsed":45631,"user":{"displayName":"Carlo Adornetto","userId":"12456770947398655820"}},"outputId":"f6ca3510-3258-4beb-e89e-1979805e981b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch 1\n","===========================================================================================================================================================================================================================================\n","Epoch 1 Train Accuracy: 0.8497\n","Epoch 1 Validation Accuracy: 0.9226\n","\n","Epoch 2\n","===========================================================================================================================================================================================================================================\n","Epoch 2 Train Accuracy: 0.9304\n","Epoch 2 Validation Accuracy: 0.9405\n","\n","Epoch 3\n","===========================================================================================================================================================================================================================================\n","Epoch 3 Train Accuracy: 0.9433\n","Epoch 3 Validation Accuracy: 0.9474\n","\n","Epoch 4\n","===========================================================================================================================================================================================================================================\n","Epoch 4 Train Accuracy: 0.9515\n","Epoch 4 Validation Accuracy: 0.9525\n","\n","Epoch 5\n","===========================================================================================================================================================================================================================================\n","Epoch 5 Train Accuracy: 0.9574\n","Epoch 5 Validation Accuracy: 0.9562\n"]}],"source":["for epoch in range(epochs):\n","    print(f\"\\nEpoch {epoch + 1}\")\n","\n","    # Trainig Loop\n","    for x_batch_train, y_batch_train in train_dataset:\n","        with tf.GradientTape() as tape:\n","            logits = model(x_batch_train, training=True)\n","            loss_value = loss_fn(y_batch_train, logits)\n","\n","        grads = tape.gradient(loss_value, model.trainable_weights)\n","        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","\n","        train_acc_metric.update_state(y_batch_train, logits)\n","        print('=', end='')\n","\n","    train_acc = train_acc_metric.result()\n","    print(f\"\\nEpoch {epoch + 1} Train Accuracy: {float(train_acc):.4f}\")\n","    train_acc_metric.reset_states()\n","\n","    # Validation Loop\n","    for x_batch_val, y_batch_val in test_dataset:\n","        val_logits = model(x_batch_val, training=False)\n","        val_acc_metric.update_state(y_batch_val, val_logits)\n","\n","    val_acc = val_acc_metric.result()\n","    print(f\"Epoch {epoch + 1} Validation Accuracy: {float(val_acc):.4f}\")\n","    val_acc_metric.reset_states()\n"]},{"cell_type":"markdown","source":["# Parametrized Custom Model"],"metadata":{"id":"msKmfgy5B6w_"}},{"cell_type":"code","source":["import tensorflow as tf\n","from keras import layers\n","\n","# Define a custom model class inheriting from tf.keras.Model\n","class MyModel(tf.keras.Model):\n","    def __init__(self, mylayers: list, out_size: int, act):\n","        super(MyModel, self).__init__()\n","        self.flatten = layers.Flatten()\n","\n","        # Create a list to store hidden layers\n","        self.hidden_layers = []\n","        # Loop through the specified neurons in `mylayers` to create hidden layers\n","        for neurons in mylayers:\n","            # Add a dense layer with the specified number of neurons and activation function\n","            self.hidden_layers.append(layers.Dense(neurons, activation=act))\n","\n","        # Define the output layer with the number of units equal to out_size\n","        # Here we assume out_size represents the number of classes in the classification task\n","        self.output_layer = layers.Dense(out_size)\n","\n","    def call(self, inputs):\n","        x = self.flatten(inputs)\n","\n","        # Pass the flattened inputs through each hidden layer in sequence\n","        for layer in self.hidden_layers:\n","            x = layer(x)\n","\n","        return self.output_layer(x)\n","\n","# Create an instance of the model with specified parameters\n","model = MyModel(mylayers=[128, 64, 16], out_size=10, act='relu')\n","\n","result = model(tf.random.normal((1, 28, 28)))\n","\n","print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CiAfLLOpB5_c","executionInfo":{"status":"ok","timestamp":1730974426313,"user_tz":-60,"elapsed":587,"user":{"displayName":"Carlo Adornetto","userId":"12456770947398655820"}},"outputId":"c5dc31a6-2b10-4bae-abcd-e45a64872d95"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[-0.6346771  -0.21130115  1.5758224  -0.153721    0.5675653   0.41883677\n","  -0.13659307 -0.6748707   0.8947159  -0.12220135]], shape=(1, 10), dtype=float32)\n"]}]},{"cell_type":"markdown","source":["# Custom Layer"],"metadata":{"id":"OdKX5xKVE8iO"}},{"cell_type":"markdown","source":["key elements:\n","\n","- **SimpleDense Class**: This class defines a custom dense (fully connected) layer with a specified number of units (neurons).\n","- **Build Method**: This is called automatically on the first input pass to the layer to initialize the layer’s weights. `self.kernel` represents the weights, while `self.bias` represents the bias term.\n","- **Call Method**: Specifies the computation logic during the forward pass. Here, it multiplies the inputs by the weights (`self.kernel`) and adds the bias (`self.bias`), representing a classic fully connected layer.\n","- **Instantiation and Testing**:\n","  - The instance `linear_layer` is created with 4 units.\n","  - When `linear_layer` is called with an input of shape `(2, 2)`, the `build` method is automatically executed to create the weights.\n","\n","**NOTE**: you can define any operations in the `call` function,  but <ins>be mindful of differentiability!</ins>"],"metadata":{"id":"g8Xpgj7oFgZW"}},{"cell_type":"code","source":["import tensorflow as tf\n","from keras.layers import Layer\n","from tensorflow import keras\n","import tensorflow.experimental.numpy as ops  # Using TensorFlow's experimental numpy ops for matmul\n","\n","# Define a custom layer class `SimpleDense`, which inherits from `Layer`\n","class SimpleDense(Layer):\n","    def __init__(self, units=32):\n","        # Initialize the base class\n","        super().__init__()\n","        # Set the number of units (neurons) for this layer\n","        self.units = units\n","\n","    # Build method to create the state of the layer (weights and biases)\n","    def build(self, input_shape):\n","        # Define and initialize the kernel (weights matrix)\n","        # `input_shape[-1]` is the size of the last dimension of the input, which matches the input features\n","        # `self.units` is the number of neurons in this layer, determining the output size\n","        self.kernel = self.add_weight(\n","            shape=(input_shape[-1], self.units),  # Shape of the weights matrix\n","            initializer=\"glorot_uniform\",         # Weight initialization method\n","            trainable=True,                       # Marks this weight as trainable\n","            name=\"kernel\",                        # Name of the weight for easier identification\n","        )\n","\n","        # Define and initialize the bias vector\n","        # The bias has a shape matching the number of units in the layer\n","        self.bias = self.add_weight(\n","            shape=(self.units,),                  # Shape of the bias vector\n","            initializer=\"zeros\",                  # Initialize bias to zero\n","            trainable=True,                       # Marks this bias as trainable\n","            name=\"bias\",                          # Name of the bias for easier identification\n","        )\n","\n","    # Call method defines the forward pass computation for the layer\n","    def call(self, inputs):\n","        # Calculate the layer output using a matrix multiplication between inputs and weights,\n","        # then add the bias term\n","        return ops.matmul(inputs, self.kernel) + self.bias\n","\n","# Instantiate the custom dense layer with 4 units\n","linear_layer = SimpleDense(4)\n","\n","# Call the layer on some input data, which will automatically call `build(input_shape)`\n","# and create the weights if they haven’t been created yet.\n","y = linear_layer(ops.ones((2, 2)))  # Passes a tensor of shape (2, 2) as input\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0t_TZ1sME4tS","executionInfo":{"status":"ok","timestamp":1730974459602,"user_tz":-60,"elapsed":519,"user":{"displayName":"Carlo Adornetto","userId":"12456770947398655820"}},"outputId":"062ef302-aaca-4129-807d-11e0de6a4fdb"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[-0.662874   -0.16512823  0.9126694   0.54519343]\n"," [-0.662874   -0.16512823  0.9126694   0.54519343]], shape=(2, 4), dtype=float32)\n"]}]}]}